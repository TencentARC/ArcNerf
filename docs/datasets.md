# base_3d_dataset
Base class for all 3d dataset. Contains image/mask(optional)/camera.
Support precache_ray/norm_cam_pose/rescale_image_pose/get_item in a uniform way.
- Each dataset contains an `identifier` that is a string separating the scene from the same dataset.
(like scan_id, scene_name, etc)

## base_3d_pc_dataset
Based on `base_3d_dataset`, it provides functions mainly on point cloud adjustment.
Points are in world coordinate.
- point_cloud: a dict with 'pts'/'color'/'vis'. Last two are optional.

# Some configs in data processing:
- img_scale: Resize image by this scale. `>1` means larger image.
Will change intrinsic for actual re-projection as well, but not change extrinsic.
- scale_radius: Rescale all camera pose such that cameras are roughly align on the surface of sphere with such radius.
Will not touch intrinsic. If point cloud exists, rescale them by same factor to keep consistency.
    - This actual cam radius will be adjusted by a factor of `1.05` which ensure cam `inside` the sphere, which will be
  good for ray-sphere computation(forbid nan).
- precache: If True, will precache all the rays for all pixels at once.
- pc_radius(base_3d_pc_dataset): Remove point cloud that are outside such absolute radius(all scaled by extra `1.05`).
Done after camera `scale_radius`. The radius is restricted within `scale_radius` range.
## Augmentation:
- n_rays: Sample `n_rays` instead of using all. But calling it every time may sample overlapping rays, not use in train.
- shuffle: shuffle all the rays from the same image together
## rgb and mask
- All color are in `rgb` order and normed by `255` into `0~1` range.
- All masks should be binary masks with `{0,1}` values. Can be [] if not exist.
## cameras
- cameras: a list of `render.camera.PerspectiveCamera`, used for ray generation.
- For every dataset, you should setup cameras by reading their own `c2w` and `intrinsic`
## rays:
- rays are generated by cameras, precache all rays if needed.
- `get_rays` generate rays in `(wh)` flatten order, but if you read by cv2 and reshape, img will be in `(hw)` order.
You need to get_rays by setting `wh_order=False` to change the order.
## point cloud
- pts: `(n_pts, 3)` in world coordinate, `xyz` order
- color: `(n_pts, 3)`, `rgb` order, should be normed into `0~1` range.
- vis: `(n_cam, n_pts)`, visibility of each point in each cam. `{0,1}` values.
- pts is required, color/vis is optional.
## bounds
- a list of bounds in `(2, )` dim representing the near, far zvals.
- If exists, help the ray sampling in modeling progress. Can be [] if not exist.
- For the near/far, you can also set in `cfgs.rays.near/far`, or use ray-sphere intersection
for near/far calculation by setting `cfgs.rays.bounding_radius`.

# Dataset Class
Below are supported dataset class.
## Capture
This class provides dataset from your capture data.
You need to run colmap to extract corresponding poses and train.
### Video_to_Image
If you capture video, you can follow `scripts/data_process.sh` to use `extract_video` to
extract video into images. Will write data to `cfgs.dir.data_dir/Capture/scene_name`
- video_path: actual video path
- scene_name: specify the scene name. Image will be written to `cfgs.dir.data_dir/Capture/scene_name/images`.
- video_downsample: downsample video frames by such factor. By default `15`.
- image_downsample: downsample each frame by such factor. By default `4`.
### Colmap Run_poses
You should install [colmap](https://colmap.github.io/) by yourself. We provide python script for processing.
you can follow `scripts/data_process.sh` to use `run_poses` to get colmap with poses and dense reconstruction.
Will write data to `cfgs.dir.data_dir/Capture/scene_name`
- match_type: `sequential_matcher` is good for sequential ordered images.
              `exhaustive_matcher` is good for random ordered image.
- dense_reconstruct: If true, run dense_reconstruct and get dense point cloud and mesh.
### Mask generation
- TODO: We may add it in the future.
### Dataset
Use `Capture` class for this dataset. It is specified by scene_name.
- scene_name: scene_name that is the folder name under `Capture`. Use it to be identifier.
#### Processing
Since we need to rescale the point_cloud and cam so that object(pc) is centered at (0,0,0). If we directly set pc.mean()
as (0,0,0), noise not on object will make the center incorrect. We do the following:
- Use all camera and ray from center image plane to get a closely approximate common view point,
which is close to object center, adjust cam/pc by this offset.
- Norm cam and point by `scale_radius` to make them within a sphere with known range.
- Filter point cloud by `pc_radius` and remove point outside.
- Recenter cam and point by setting the filtered point cloud center as (0,0,0).
- Re-norm cam and point again to make cam on the surface of sphere with `scale_radius` and obj is centered.

We test and show that the method is robust to make the coordinate system such that object is centered at (0,0,0),
cam is on surface with `scale_radius`. Only scale and translation is applied, do not affect the intrinsic.

## DTU
Specified by scan_id, read image/mask/camera.
- scan_id: int num for item selection. Use it to be identifier.


# Train/Val/Eval/Inference

## Train
Use all images for training. Same resolution as required.

For training, we should read all rays from all images together, shuffle each image pixels(rays), shuffle images,
concat all the image, sample in batch with `n_rays`. Each epoch just trained on batch. When all rays from all images
have been chosen, shuffle again.


## Val
Use all images for validation, downsampled by 2/4 depends on shape.

Each valid epoch just input one image for rendering, so the batch_size for val is cast to be 1.


## eval
Use several closest camera(to avg_cam) for metric evaluation,

use same resolution(Or scale if image really too large), and use custom cam paths for rendering video

- eval_batch_size: batch size for eval
- eval_max_sample: max num of sample in eval dataset.
only those will be fully rendered can calculate metric.


## inference
Inference will be performed based on eval dataset params(intrinsic, img shape).

- render: controls the params of render novel view, like the camera path
- volume: controls the params of volume estimation and mesh extraction/rendering.
