{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab017886-5449-442d-a211-55cabf816022",
   "metadata": {},
   "source": [
    "# Setup your project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c580ca-fdfc-48e1-a33c-4f5814158384",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /group/30042/leoyluo/Immerse/projects/ArcNerf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c9fbf-887a-4d57-a448-90ee08a5d0bf",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42f0ea-a494-48a8-a3ad-bebe70dcd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from arcnerf.geometry.mesh import (\n",
    "    extract_mesh,\n",
    "    get_normals,\n",
    "    get_face_centers,\n",
    "    get_verts_by_faces,\n",
    "    simplify_mesh\n",
    ")\n",
    "from arcnerf.geometry.volume import Volume\n",
    "from arcnerf.models import build_model\n",
    "from arcnerf.visual.plot_3d import draw_3d_components\n",
    "from common.utils.cfgs_utils import load_configs\n",
    "from common.utils.logger import Logger\n",
    "from common.utils.model_io import load_model\n",
    "from common.utils.torch_utils import torch_to_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c752d6-552d-4883-b8ea-94f77c6da467",
   "metadata": {},
   "source": [
    "# Specify the model cfgs and model_pt with device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993baf45-218e-41e4-a9a6-51cc9dfeee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs_file = '/group/30042/leoyluo/Immerse/projects/ArcNerf/configs/inference.yaml'\n",
    "model_pt = '/group/30042/leoyluo/Immerse/projects/ArcNerf/experiments/capture_qqtiger_nerf/checkpoints/final.pt.tar'\n",
    "device = 'gpu'  # 'cpu' or 'gpu'\n",
    "\n",
    "assert os.path.exists(cfgs_file), 'cfgs not exist at {}'.format(cfgs_file)\n",
    "assert os.path.exists(model_pt), 'model file not exist at {}'.format(model_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdefb5ae-9114-448e-bc65-e3285ec693b0",
   "metadata": {},
   "source": [
    "# Set up cfgs, device, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb98b44-f311-4fef-9acd-04c825abb9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = load_configs(cfgs_file)\n",
    "logger = Logger()\n",
    "\n",
    "if torch.cuda.is_available() and device == 'gpu':\n",
    "    torch.cuda.set_device(0)\n",
    "    \n",
    "model = build_model(cfgs, None)\n",
    "model = load_model(logger, model, None, model_pt, cfgs)\n",
    "if device == 'gpu':\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2299583-4002-401c-b1fe-abd8676336b3",
   "metadata": {},
   "source": [
    "# Set volume params and get volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b56d21-5f43-4449-8b73-9f1929b831fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grid = 128                 # n_grid is the num of voxel in each dim. For visual set a small num only\n",
    "side = 1.5                   # if set, all len at each dim will be side\n",
    "# xyz_len if you find the extract volume is not a cube\n",
    "grad_dir = 'descent'         # if 'descent', sigma is larger than level in obj(NeRF), if 'ascent' is smaller(SDF)\n",
    "\n",
    "chunk_pts_factor= 32         # process more pts together\n",
    "model.set_chunk_pts(model.get_chunk_pts() * chunk_pts_factor)\n",
    "\n",
    "# volume \n",
    "volume = Volume(n_grid, side=side)\n",
    "volume_pts = volume.get_volume_pts()  # (n_grid^3, 3) pts in torch\n",
    "volume_size = volume.get_voxel_size()  # (3,) tuple\n",
    "volume_len = volume.get_len()  # (3,) tuple\n",
    "dtype = volume_pts.dtype\n",
    "if device == 'gpu':\n",
    "    volume_pts = volume_pts.cuda()\n",
    "\n",
    "# for visual\n",
    "corner = torch_to_np(volume.get_corner())\n",
    "bound_lines = volume.get_bound_lines()\n",
    "volume_dict = {'grid_pts': corner, 'lines': bound_lines}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad44475-6a7a-4987-ada2-48e977170967",
   "metadata": {},
   "source": [
    "# Get point cloud from volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03f4ff-b93c-49bb-818b-b107de884066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get init sigma\n",
    "time0 = time.time()\n",
    "sigma, rgb = model.forward_pts_dir(volume_pts, None)\n",
    "sigma, rgb = torch_to_np(sigma), torch_to_np(rgb)\n",
    "print('Forward {}^3 time for model is {:.2f}s'.format(n_grid, time.time() - time0))\n",
    "print('Sigma value range {:.2f}-{:.2f}'.format(sigma.min(), sigma.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0af2b4-8e64-49e0-878d-d836f6af359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sigma based on sigma output\n",
    "level = 50.0                 # sigma level to extract mesh from volume  \n",
    "\n",
    "# get valid sigma\n",
    "if grad_dir == 'descent':\n",
    "    valid_sigma = (sigma >= level)  # (n^3,)\n",
    "else:\n",
    "    valid_sigma = (sigma <= level)  # (n^3,)\n",
    "\n",
    "# set max_pts pts, get pts and show pts\n",
    "max_pts=200000\n",
    "\n",
    "valid_pts = torch_to_np(volume_pts)[valid_sigma]  # (n_valid, 3)\n",
    "valid_rgb = rgb[valid_sigma]  # (n_valid, 3)\n",
    "print('Getting {} valid pts'.format(valid_pts.shape[0]))\n",
    "n_pts = valid_pts.shape[0]\n",
    "\n",
    "if n_pts > max_pts:\n",
    "    print('Sample to {} pts'.format(max_pts))\n",
    "    choice = np.random.choice(range(n_pts), max_pts, replace=False)\n",
    "    valid_pts = valid_pts[choice]\n",
    "    valid_rgb = valid_rgb[choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14548044-15b8-4d6a-ac32-0ca6d3782432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw 3d pts\n",
    "draw_3d_components(\n",
    "    points=valid_pts,\n",
    "    point_colors=valid_rgb,\n",
    "    point_size=10,\n",
    "    volume=volume_dict,\n",
    "    title='valid pts({}) from volume'.format(valid_pts.shape[0]),\n",
    "    plotly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac453c24-464a-4749-a2d5-7c50bfeb40ef",
   "metadata": {},
   "source": [
    "# Get Mesh from volume using density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b8fc5-3f33-4644-902c-3de4b7714daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract original mesh\n",
    "sigma = sigma.reshape((n_grid, n_grid, n_grid))  # (n, n, n)\n",
    "time0 = time.time()\n",
    "verts, faces, _ = extract_mesh(sigma.copy(), level, volume_size, volume_len, grad_dir)\n",
    "print('Extract mesh time {:.2f}s'.format(time.time() - time0))\n",
    "print('Extract {} verts, {} faces'.format(verts.shape[0], faces.shape[0]))\n",
    "\n",
    "# simplify for 3d visual, get colors\n",
    "max_faces=200000\n",
    "if faces.shape[0] > max_faces:\n",
    "    verts, faces = simplify_mesh(verts, faces, max_faces)\n",
    "    print('    Simplify mesh time {:.2f}s'.format(time.time() - time0))\n",
    "    print('    Simplify {} verts, {} faces'.format(verts.shape[0], faces.shape[0]))\n",
    "\n",
    "n_verts, n_faces = verts.shape[0], faces.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb062129-a357-4fb6-a584-48e39bbc13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear gpu memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# get components like normal, color\n",
    "vert_normals, face_normals = get_normals(verts, faces)\n",
    "face_centers = get_face_centers(verts, faces)\n",
    "\n",
    "# get face_colors, view point is the reverse normal\n",
    "face_view_dir = -face_normals\n",
    "face_center_pts = torch.tensor(face_centers, dtype=dtype)  # (n, 3)\n",
    "face_view_dir = torch.tensor(face_view_dir, dtype=dtype)  # (n, 3)\n",
    "\n",
    "# move to gpu\n",
    "if device == 'gpu':\n",
    "    face_center_pts = face_center_pts.cuda()\n",
    "    face_view_dir = face_view_dir.cuda()\n",
    "\n",
    "time0 = time.time()\n",
    "_, face_colors = model.forward_pts_dir(face_center_pts, face_view_dir)\n",
    "face_colors = torch_to_np(face_colors)\n",
    "print('Get faces color for all {} faces takes {:.2f}s'.format(n_faces, time.time() - time0))\n",
    "\n",
    "# verts from (V, 3) to (F, 3, 3)\n",
    "verts_by_faces, _ = get_verts_by_faces(verts, faces, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f838e5-785d-4f3c-bf99-be782ba095ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw 3d mesh\n",
    "draw_3d_components(\n",
    "    volume=volume_dict,\n",
    "    meshes=[verts_by_faces],\n",
    "    face_colors=[face_colors],\n",
    "    title='Meshes ({} faces) extract from volume'.format(verts_by_faces.shape[0]),\n",
    "    plotly=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
