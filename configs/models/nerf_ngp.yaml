# The NeRF model with embedder from instant-ngp

model:
    type: NeRF
    rays:
        bounding_radius: 3.0          # bounding ray sampling region
        near: 1.5                     # hardcode near zvals
        far: 4.5                      # hardcode far zvals
        n_sample: 64                  # n_sample for zvals sampling
        n_importance: 128             # n_importance for zvals for hierarchical sampling
        inverse_linear: False         # inverse_linear make zvals close to near
        perturb: True                 # perturb zvals interval
        add_inf_z: True               # Add inf zval for ray marching
        noise_std: 1.0                # noise for sigma in training
        white_bkg: False              # cast the background as white
    chunk_rays: 32768                 # each chunk to process 1024*32(ray), enough for 32 GB
    chunk_pts: 131072                 # each chunk to progress 4096*32(pts), for model forward
    geometry:
        W: 64                         # linear hidden neuron
        D: 1                          # num of linear, not include final
        skips: []                     # pos to add input embedding
        encoder:                      # encoder
            type: HashGridEmbedder    # type of encoder
            input_dim: 3              # xyz input channel
            n_freqs: 0                # this one controls the geo init
            n_levels: 16              # num of levels for multi-res hashing, increase from base_res to max_res
            n_feat_per_entry: 2       # num of feat in each entry
            hashmap_size: 19          # 2**hashmap_size for hashmap size in each bin
            base_res: 16              # base res on each xyz dim
            max_res: 512              # last res
            backend: tcnn             # backend: support torch/cuda/tcnn
        W_feat: 16                    # extra feature output
        geometric_init: False         # whether to use geometric init. need radius_init
    radiance:
        mode: 'vf'                    # view_dir and feature only
        W: 64                         # linear hidden dim
        D: 2                          # num of linear, not include final
        encoder:
            view:
                type: SHEmbedder      # type of encoder
                input_dim: 3          # view input channel
                n_freqs: 4            # view embed freq, output is degree**2
                backend: tcnn         # backend: support torch/cuda/tcnn
        W_feat_in: 16                 # dim for feature from geometry
