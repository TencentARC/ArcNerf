# inference script

name: inference

model_pt: '/group/30042/leoyluo/Immerse/projects/ArcNerf/experiments/capture_qqtiger_nerf/checkpoints/final.pt.tar'

dir:
    data_dir: None
    eval_dir: '/group/30042/leoyluo/Immerse/projects/ArcNerf/results/capture_qqtiger_nerf'

gpu_ids: -1                   # -1 for cpu, 0/1/2 for gpu. Do not use multiple gpu

dist:
    rank: 0
    local_rank: 0
    world_size: 1

dataset:
    eval:       # for getting intrinsic
        eval_max_sample: 1
        type: Capture
        scene_name: qqtiger
        img_scale: 0.25
        scale_radius: 3.0
        pc_radius: 2.0
        skip: 10
        align_cam: False
        precache: False

inference:
    # set render if you want to render view
    render:                         # set a list of render camera on sphere
        type: [circle, spiral]      # list of render cam type
        n_cam: [20, 20]             # each render type num of cam
        repeat: [3, 3]              # repeat the render video
        radius: 3.0                 # sphere radius
        u_start: 0.0                # for start pos u in (0~1)
        u_range: [0.0, 0.5]         # u in (0~1) for swing mode only
        v_ratio: 0.0                # for circle path, vertical position
        v_range: [-0.5, 0]          # for spiral path, vertical pos range
        normal: [0.0, 1.0, 0.0]     # for cam path rotation, (0,1,0) is horizontal without rotation
        n_rot: 3                    # n_rot of camera path
        reverse: False              # reverse u range for swing mode only
        fps: 5                      # render video fps
        # surface_render:           # whether to add surface rendering, good for sdf model
        #     chunk_rays_factor: 1024 # set this to allow model to process more rays in surface_render mode
        #     method: sphere_tracing  # method to find surface pts, ['sphere_tracing', 'secant_root_finding']
        #     n_step: 128           # used for secant_root_finding, split the whole ray into intervals. By default 128
        #     n_iter: 20            # num of iter to run finding algorithm. By default 20
        #     threshold: 0.01       # error bounding to stop the iteration. By default 0.01
        #     level: 0.0            # level set for mesh extracting. For sigma is around 50. For sdf is 0.
        #     grad_dir: ascent      # if 'descent', sigma is larger than level in obj(NeRF), if 'ascent' is smaller(SDF)

    # set volume if you want to extract mesh
    volume:                         # volume params
        origin: [0.0, 0.0, 0.0]     # volume center
        n_grid: 512                 # n_grid is the num of voxel in each dim. For visual set a small num only
        side: 1.5                   # if set, all len at each dim will be side
        # xyz_len: [1.0, 1.0, 1.0]  # xyz-dim length, only when side is None
        level: 50.0                 # level set for mesh extracting. For sigma is around 50. For sdf is 0.
        grad_dir: descent           # if 'descent', sigma is larger than level in obj(NeRF), if 'ascent' is smaller(SDF)
        chunk_pts_factor: 32        # set this to allow model to process more pts in pts_dir forward mode
        render_mesh:                # If True, will render the extracted mesh(in color and geo only)
            backend: pytorch3d      # Select the render backend type. (Open3d, pytorch3d)

model:
    type: NeRF
    rays:
        bounding_radius: 3.0          # bounding ray sampling region
        near: 1.0                     # hardcode near zvals
        far: 8.0                      # hardcode far zvals
        n_sample: 64                  # n_sample for zvals sampling
        n_importance: 128             # n_importance for zvals for hierarchical sampling
        inverse_linear: False         # inverse_linear make zvals close to near
        perturb: True                 # perturb zvals interval
        add_inf_z: True               # Add inf zval for ray marching, do not applied for background
        noise_std: 1.0                # noise for sigma in training
        white_bkg: False              # cast the background as white
    chunk_rays: 32768                 # each chunk to process 1024*32(ray), enough for 32 GB
    chunk_pts: 131072                 # each chunk to progress 4096*32(pts), for model forward
    geometry:
        W: 256                        # linear hidden neuron
        D: 8                          # num of linear, not include final
        skips: [4]                    # pos to add input embedding
        encoder:                      # encoder
            type: FreqEmbedder        # type of encoder
            input_dim: 3              # xyz input channel
            n_freqs: 10               # xyz embed freq
        W_feat: 256                   # extra feature output
        geometric_init: False         # whether to use geometric init. need radius_init
    radiance:
        mode: 'vf'                    # view_dir and feature only
        W: 128                        # linear hidden dim
        D: 1                          # num of linear, not include final
        encoder:
            view:
                type: FreqEmbedder    # type of encoder
                input_dim: 3          # view input channel
                n_freqs: 4            # view embed freq
        W_feat_in: 256                # dim for feature from geometry
